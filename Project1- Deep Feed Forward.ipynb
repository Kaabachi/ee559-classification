{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Project 1 - Multi-layer perceptron </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to test different architectures to compare two digits visible in a\n",
    "two-channel image. It aims at showing in particular the impact of weight sharing, and of the use of an\n",
    "auxiliary loss to help the training of the main objective.\n",
    "It should be implemented with PyTorch only code, in particular without using other external libraries\n",
    "such as scikit-learn or numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the data sets to using with the function generate_pair_sets(N) defined in the file\n",
    "dlc_practical_prologue.py. This function returns six tensors:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name          | Tensor dimension | Type     | Content                                    |\n",
    "|---------------|------------------|----------|--------------------------------------------|\n",
    "| train_input   | N × 2 × 14 × 14  | float32  | Images                                     |\n",
    "| train_target  | N                | int64    | Class to predict ∈ {0, 1}                  |\n",
    "| train_classes | N × 2            | int64    | Classes of the two digits ∈ {0, . . . , 9} |\n",
    "| test_input    | N × 2 × 14 × 14  | float32  | Images                                     |\n",
    "| test_target   | N                | int64    | Class to predict ∈ {0, 1}                  |\n",
    "| test_classes  | N × 2            | int64    | Classes of the two digits ∈ {0, . . . , 9} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 392])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_input.view(1000,-1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(392, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, nb_hidden)\n",
    "        self.fc4 = nn.Linear(nb_hidden, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x= self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected Neural Network 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 25\n",
    "def train_model(model,train_input,train_target):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = 0.2)\n",
    "    for e in range(0,n_epochs):\n",
    "        for input, targets in zip(train_input.split(batch_size),train_target.split(batch_size)):\n",
    "            output = model(input)\n",
    "            loss = criterion(output,targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if(e%5 ==0):\n",
    "            print('epoch : ',e,' loss : ',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  loss :  0.6932509541511536\n",
      "epoch :  50  loss :  0.3233296871185303\n",
      "epoch :  100  loss :  0.3232756555080414\n",
      "epoch :  150  loss :  0.3232681155204773\n",
      "epoch :  200  loss :  0.32326576113700867\n"
     ]
    }
   ],
   "source": [
    "model = Net(200)\n",
    "train_model(model,train_input.view(1000,-1),train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model,data_input,data_target):\n",
    "    nb_errors = 0\n",
    "    for input,targets in zip(data_input.split(batch_size),data_target.split(batch_size)):\n",
    "        output = model(input)\n",
    "        _,predicted_classes = torch.max(output,1)\n",
    "        for i in range(0,output.size(0)):\n",
    "            if(predicted_classes[i]!=targets[i]):\n",
    "                nb_errors = nb_errors+1\n",
    "                \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 1.60% test_error 19.10%\n"
     ]
    }
   ],
   "source": [
    "print('train_error {:.02f}% test_error {:.02f}%'.format(\n",
    "    compute_nb_errors(model, train_input.view(1000,-1), train_target) / train_input.size(0) * 100,\n",
    "    compute_nb_errors(model, test_input.view(1000,-1), test_target) / test_input.size(0) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d1e0ddd59ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m392\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;31m# print(type(x[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (392))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
